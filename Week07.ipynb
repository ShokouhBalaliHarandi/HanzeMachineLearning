{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description:\n",
    "\n",
    "This assignment focuses on building and evaluating different classifiers for breast cancer classification using the breast cancer dataset. The classifiers implemented include Bagging, Boosting, and a Dummy Classifier.\n",
    "\n",
    "#### data science pipeline\n",
    "\n",
    "1. **Understanding the Dataset**: understanding of the dataset by reviewing the dataset documentation and exploring the features.\n",
    "\n",
    "2. **Load the Data**: Reading the dataset file (`breast-cancer.csv`) and load it.\n",
    "\n",
    "3. **Exploratory Analysis**: Performing exploratory data analysis to reach insights into the dataset. This include visualizations and statistical summaries.\n",
    "\n",
    "4. **Data Preprocessing**: Applying necessary preprocessing steps such as handling missing values, handling skewness, and normalizing the data.\n",
    "\n",
    "5. **Modeling**: Creating and training different classifiers. Implement Bagging classifiers with various estimators and a Dummy Classifier.\n",
    "\n",
    "6. **Evaluation**: Evaluating the performance of the classifiers using appropriate evaluation metrics such as accuracy, precision, recall, and F1-score. Compare the performance of different models and analyze why some methods perform better than others. Experiment with different configurations for Bagging and Boosting models.\n",
    "\n",
    "7. **Visualization**: Visualization the results and evaluation metrics using appropriate plots. Plot the Precision-Recall Curve for decision tree and random forest classifiers. Additionally, generate feature importance plots for the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading data & exploratory analysis\n",
    "\n",
    "In this part, the breast cancer dataset is read and the first few rows are displayed to have overview of data and types of them.\n",
    "\n",
    "After that,  dataset's information including column names, data types, and non-null counts are printed to achieve more detail of breast cancer data status and also the distribution of the target variable 'diagnosis' which indicates the counts of malignant (M) and benign (B) is checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "configPath = 'config.yaml'\n",
    "\n",
    "# Read the yaml data from the file\n",
    "with open(configPath, 'r') as file:\n",
    "    configData = yaml.safe_load(file)\n",
    "\n",
    "df = pd.read_csv(configData[\"breast_cancer_path\"])\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting an overview of the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above results show, it seems there is no null values in the data, but in the following code we will double check it with static methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of target variable\n",
    "print(df['diagnosis'].value_counts())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagnosis columns involves 357 B class and 212 M class. and as previouse part showed there is no non-value feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization the distribution of features\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.drop(['id'], axis=1).hist(bins=30, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distrbution of features expect 'id' field are checked and regarding the right tail it seems that the data are not normalized.\n",
    "\n",
    "Id field is not important field in this assignment and don't give significant data for breast cancer status in this assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing data\n",
    "\n",
    "As the 'diagnosis' column is an categorical, it is encoded for the classifiers to work with numeric labels.\n",
    "\n",
    "Also, data for furture calculations are splitted to dependent(/target) variable ('diagnosis column) and independent (features) variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, the missing value are handled with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the diagnosis column (Malignant = 1, Benign = 0)\n",
    "label_encoder = LabelEncoder()\n",
    "df['diagnosis'] = label_encoder.fit_transform(df['diagnosis'])\n",
    "\n",
    "# Split the data into features (X) and target(dependent) variable (y)\n",
    "X = df.drop(['id', 'diagnosis'], axis=1)\n",
    "y = df['diagnosis']\n",
    "\n",
    "# handling missing values (replace them with mean)\n",
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the code identifies features with skewness above a threshold of 0.7. Skewness indicates the asymmetry of the distribution of a feature. The code then applies a power transformation to these skewed features to make their distributions more symmetric and closer to a normal distribution. \n",
    "\n",
    "After that, the features using standard scaling, which ensures that each feature has a mean of 0 and a standard deviation of 1. This helps improve the performance of many machine learning algorithms that are sensitive to the scale of features. \n",
    "\n",
    "The following part is done because of the result of exploratory analysis that showed there is a different variance between data.\n",
    "\n",
    "Finally, the test and train data are created based on prepared data for the rest analysis of breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Calculating skewness of the features\n",
    "skewness = X.skew()\n",
    "\n",
    "# Selecting features with skewness above a threshold (0.7)\n",
    "skewed_features = skewness[abs(skewness) > 0.7].index\n",
    "\n",
    "# Applying power transformation \n",
    "power_transformer = PowerTransformer()\n",
    "X_skewed = X[skewed_features].copy()\n",
    "X_skewed_transformed = power_transformer.fit_transform(X_skewed)\n",
    "\n",
    "# Replacing the original skewed features with the transformed features\n",
    "X[skewed_features] = X_skewed_transformed\n",
    "\n",
    "# Normalizing the features using standard scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the bagging, boosting, and dummy classifiers\n",
    "\n",
    "Here, different instances of Bagging and AdaBoost classifiers are created with varying numbers of estimators. The BaggingClassifier combines multiple base estimators to improve model performance, while AdaBoostClassifier adapts its focus on samples that were misclassified by the previous estimator. A DummyClassifier is used as a baseline that always predicts the most frequent class.\n",
    "\n",
    "Increasing the number of estimators can improve performance, but it increases computation time, as well; Because of this in the following just 15, 10 and 5 values is used for estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging Classifier with different estimator\n",
    "bagging_clf_15 = BaggingClassifier(n_estimators=15, random_state=random_seed)\n",
    "bagging_clf_10 = BaggingClassifier(n_estimators=10, random_state=random_seed)\n",
    "bagging_clf_5 = BaggingClassifier(n_estimators=5, random_state=random_seed)\n",
    "\n",
    "# AdaBoost Classifier with different estimator\n",
    "adaboost_clf_15 = AdaBoostClassifier(n_estimators=15, random_state=random_seed)\n",
    "adaboost_clf_10 = AdaBoostClassifier(n_estimators=10, random_state=random_seed)\n",
    "adaboost_clf_5 = AdaBoostClassifier(n_estimators=5, random_state=random_seed)\n",
    "\n",
    "# Dummy Classifier as a baseline\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, the classifiers are trained with the training data and then used to predict the labels of the test data to used in the evaluatation models' part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Bagging Classifier\n",
    "bagging_clf_15.fit(X_train, y_train)\n",
    "bagging_pred_15 = bagging_clf_15.predict(X_test)\n",
    "\n",
    "bagging_clf_10.fit(X_train, y_train)\n",
    "bagging_pred_10 = bagging_clf_10.predict(X_test)\n",
    "\n",
    "bagging_clf_5.fit(X_train, y_train)\n",
    "bagging_pred_5 = bagging_clf_5.predict(X_test)\n",
    "\n",
    "# Train and evaluate AdaBoost Classifier\n",
    "adaboost_clf_15.fit(X_train, y_train)\n",
    "adaboost_pred_15 = adaboost_clf_15.predict(X_test)\n",
    "\n",
    "adaboost_clf_10.fit(X_train, y_train)\n",
    "adaboost_pred_10 = adaboost_clf_10.predict(X_test)\n",
    "\n",
    "adaboost_clf_5.fit(X_train, y_train)\n",
    "adaboost_pred_5 = adaboost_clf_5.predict(X_test)\n",
    "\n",
    "# Train and evaluate Dummy Classifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_pred = dummy_clf.predict(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Evaluation\n",
    "\n",
    "The predictions calculated in the above section are used to evaluate the models' performance using various evaluation metrics like accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'F1-score': f1_score\n",
    "}\n",
    "\n",
    "#this function evaluate the specific model based on defined metrics and prediction set\n",
    "def evaluate_model(model, predictions):\n",
    "    eval_results = {}\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        if model.classes_[0] == 'B':\n",
    "            label_mapping = {'B': 0, 'M': 1}\n",
    "            y_test_mapped = y_test.map(label_mapping)\n",
    "            predictions_mapped = [label_mapping[pred] for pred in predictions]\n",
    "        else:\n",
    "            y_test_mapped = y_test\n",
    "            predictions_mapped = predictions\n",
    "        eval_results[metric_name] = metric_func(y_test_mapped, predictions_mapped)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Bagging Classifier\n",
    "bagging_results_15 = evaluate_model(bagging_clf_15, bagging_pred_15)\n",
    "bagging_results_10 = evaluate_model(bagging_clf_10, bagging_pred_10)\n",
    "bagging_results_5 = evaluate_model(bagging_clf_5, bagging_pred_5)\n",
    "\n",
    "# Evaluating AdaBoost Classifier\n",
    "adaboost_results_15 = evaluate_model(adaboost_clf_15, adaboost_pred_15)\n",
    "adaboost_results_10 = evaluate_model(adaboost_clf_10, adaboost_pred_10)\n",
    "adaboost_results_5 = evaluate_model(adaboost_clf_5, adaboost_pred_5)\n",
    "\n",
    "# Evaluating Dummy Classifier\n",
    "dummy_results = evaluate_model(dummy_clf, dummy_pred)\n",
    "\n",
    "# Displaying the results\n",
    "print('Bagging Classifier Results:')\n",
    "print(\"15 estimator\", bagging_results_15)\n",
    "print(\"10 estimator\", bagging_results_10)\n",
    "print(\"5 estimator\", bagging_results_5)\n",
    "print('\\nAdaBoost Classifier Results:')\n",
    "print(\"15  estimator\", adaboost_results_15)\n",
    "print(\"10 estimator\", adaboost_results_10)\n",
    "print(\"5  estimator\", adaboost_results_5)\n",
    "print('\\nDummy Classifier Results:')\n",
    "print(dummy_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Bagging Classifier and the AdaBoost Classifier evaluation results based on all metrics has a high score (over 90%), it shows that both are performing well, and also the AdaBoost Classifier having slightly better results, especially when using a smaller number of estimators (5). \n",
    "\n",
    "The Dummy Classifier, on the other hand, is performing poorly and isn't providing meaningful predictions for given breast cancer data. It reaches an accuracy of about 62.28%, but it has very low precision, recall, and F1-score, all being 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization results\n",
    "\n",
    "In the following, the results of each model with estimators are plotted with confusion matrix and ROC curve.\n",
    "\n",
    "The confusion matrix shows the counts of true positive, true negative, false positive, and false negative predictions of breast cancer data, while the ROC curve illustrates the trade-off between true positive rate and false positive rate.\n",
    "\n",
    "As in the above section, Dummy Classifier didn't reach to the proper results in the following is not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve\n",
    "\n",
    "# ploting the result of Confusion Matrix\n",
    "\n",
    "class_names = ['Benign', 'Malignant']\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 18))\n",
    "\n",
    "# 15 estimators\n",
    "plot_confusion_matrix(bagging_clf_15, X_test, y_test, display_labels=class_names, cmap=plt.cm.Blues, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Bagging (15 Estimators)\")\n",
    "plot_confusion_matrix(adaboost_clf_15, X_test, y_test, display_labels=class_names, cmap=plt.cm.Blues, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Adaboost (15 Estimators)\")\n",
    "\n",
    "# 10 estimators\n",
    "plot_confusion_matrix(bagging_clf_10, X_test, y_test, display_labels=class_names, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Bagging (10 Estimators)\")\n",
    "plot_confusion_matrix(adaboost_clf_10, X_test, y_test, display_labels=class_names, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Adaboost (10 Estimators)\")\n",
    "\n",
    "# 5 estimators\n",
    "plot_confusion_matrix(bagging_clf_5, X_test, y_test, display_labels=class_names, cmap=plt.cm.Greens, ax=axes[2, 0])\n",
    "axes[2, 0].set_title(\"Bagging (5 Estimators)\")\n",
    "plot_confusion_matrix(adaboost_clf_5, X_test, y_test, display_labels=class_names, cmap=plt.cm.Greens, ax=axes[2, 1])\n",
    "axes[2, 1].set_title(\"Adaboost (5 Estimators)\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above figures both models with all estimators works well (all have error type 1 and 2 under 5) but like the previouse section the Adaboost works better than baggin especially with 5 estimators which has 2 FN and 0 FP.\n",
    "\n",
    "FN: means model predicted 'Benign' but the actual result was 'Malignant'\n",
    "\n",
    "FP: means model predicted 'Malignant' but the actual result was 'Benign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the result of roc curve \n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 18))\n",
    "\n",
    "# 15 estimators\n",
    "plot_roc_curve(bagging_clf_15, X_test, y_test, ax=axes[0, 0])\n",
    "axes[0, 0].set_title(\"Bagging (15 Estimators)\")\n",
    "plot_roc_curve(adaboost_clf_15, X_test, y_test, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Adaboost (15 Estimators)\")\n",
    "\n",
    "# 10 estimators\n",
    "plot_roc_curve(bagging_clf_10, X_test, y_test, ax=axes[1, 0])\n",
    "axes[1, 0].set_title(\"Bagging (10 Estimators)\")\n",
    "plot_roc_curve(adaboost_clf_10, X_test, y_test, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Adaboost (10 Estimators)\")\n",
    "\n",
    "# 5 estimators\n",
    "plot_roc_curve(bagging_clf_5, X_test, y_test, ax=axes[2, 0])\n",
    "axes[2, 0].set_title(\"Bagging (5 Estimators)\")\n",
    "plot_roc_curve(adaboost_clf_5, X_test, y_test, ax=axes[2, 1])\n",
    "axes[2, 1].set_title(\"Adaboost (5 Estimators)\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods with their estimators have almost same results just AdaBoost Classifier with 5 estimators covers its Area under the curve (AUC) more than others in the almost 0.99 scores. So it shows this type of model slightly works better than others. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance Plot\n",
    "\n",
    "As in the previouse part the AdaBoost classifier with 5 estimators works better than others in this section, feature importances are calculated for this model and Bagging with 5 estimators as well to compare with each other and see the differences in importance features of breast cancer.\n",
    "\n",
    "Feature importance indicates how much each feature contributes to the model's predictions. The code then sorts and plots these importances for each estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# for bagging\n",
    "importances_5 = bagging_clf_5.estimators_[0].feature_importances_\n",
    "feature_names = X.columns # Getting feature names\n",
    "indices_5 = np.argsort(importances_5)[::-1] # Sorting feature importances in descending order\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X.shape[1]), importances_5[indices_5])\n",
    "plt.xticks(range(X.shape[1]), feature_names[indices_5], rotation=90)\n",
    "plt.title('Feature Importance of Adaboost with 5 estimators')\n",
    "plt.show()\n",
    "\n",
    "#for adaboost\n",
    "importances_5 = adaboost_clf_5.estimators_[0].feature_importances_\n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices_5 = np.argsort(importances_5)[::-1]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X.shape[1]), importances_5[indices_5])\n",
    "plt.xticks(range(X.shape[1]), feature_names[indices_5], rotation=90)\n",
    "plt.title('Feature Importance of Adaboost with 5 estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above the main feature that impact on the model for prediction of breast cancer in Adaboost classifier with 5 estimator is \"concave points_mean\", meanwhile for bagging with the same estimators there are 8 features that have main role in prediction and the most important is \"perimeter_worst\" feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
