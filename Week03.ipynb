{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Description: \n",
    "\n",
    "Improving Data Quality for Anomaly Detection in Time Series Data. (Anomaly detection in time series data better at finding unusual patterns by using a set of steps to clean and organize it.)\n",
    "\n",
    "Main assignment worked with time series data from sensor readings, which often contain outliers due to sensor errors and noise. In this assignment common data preprocessing techniques is implemented to improve data quality while maintaining the integrity of actual anomalies present in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading data\n",
    "\n",
    "At first I read the data and invest primiary featues to check if data in proper status in size and type format for more analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Import the data\n",
    "\n",
    "configPath = 'config.yaml'\n",
    "\n",
    "# Read the yaml data from the file\n",
    "with open(configPath, 'r') as file:\n",
    "    configData = yaml.safe_load(file)\n",
    "\n",
    "df = pd.read_csv(configData[\"sensor_path\"])\n",
    "\n",
    "print(f'size of data: {df.shape}') # get the size of data\n",
    "\n",
    "print(df.head(5))\n",
    "\n",
    "# df.info which is used in previouse version is done both functions togther (print the data and shape of them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the total recorded observation are 220320. First column is such a sequential column and the second column is timestamp for save the observations' times. and the last column is a categorical column which determines the status of machine on specific time.\n",
    "\n",
    "Now, it is needed to get the type of columns to be sure about the format of data regards the printed sample of data in the above block and convert types of it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sensor columns (52 columns) have float64 type.\n",
    "\n",
    "As this assignment is about machines' abormaly detection, so \"machine_status\" field is assumed as a target field. So the value of it is important to recognize which value shows everything goes well for machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"machine_status\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By above values, 'NORMAL' value is assumed as a normal status of machines for the rest of assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One the steps that can do in for data is removing outerlines or the data are faced by too much errors in the measuring and has missing values. To find the low-quality columns and remove them from the data, in the following code the missing values are used. high percentage of missing values are assumed as a low-quality sensors. \n",
    "\n",
    "To find the high percentages of missing values 2 approach are possible, make the threshold or investing the values and remove top n scores. In the following the 30% threshold is used. Besides the scores are sorted to have a view and compare it with the threshold result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating percentage of missing values\n",
    "missing_perc = df.isnull().sum() / len(df) * 100\n",
    "\n",
    "# Identifing columns with high missing percentage (threshold > 30%)\n",
    "low_quality_cols = missing_perc[missing_perc > 30].index.tolist()\n",
    "\n",
    "print(f'low quality columns are: {low_quality_cols}')\n",
    "\n",
    "print(missing_perc.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'sensor_15', 'sensor_50' have most missing values regarding the threshold, however, by observing the sorted percentage these sensors have a most missing values and other sensors have much more lower percentages. By knowing this data, the low quality sensors can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing low-quality columns\n",
    "df.drop(low_quality_cols, inplace=True, axis=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 sensors are removed and the amount of columns gets 53. In this step, the format of data and other missing values are adjusted to have the proper data for the rest of the analysis and resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values mean value\n",
    "df = df.fillna(df.mean(axis=1))\n",
    "\n",
    "# Converting timestamp column to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Setting timestamp as the index\n",
    "df = df.set_index('timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce noises and highlight higher-level patterns, data are resampled to a lower frequency. For this aim data are aggregated over time intervals (daily) by taking the mean values. And after that again the missing values are adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data to a lower frequency (daily mean)\n",
    "df_resampled = df.resample('D').mean()\n",
    "\n",
    "# Handle missing values in the resampled data\n",
    "df_resampled = df_resampled.interpolate(method='linear')\n",
    "\n",
    "print(f'size of resampled data: {df_resampled.shape}')\n",
    "\n",
    "print(df_resampled.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data are aggregated in day and the status column is automatically is removed because it was categorical feature. So we just have 51 sensors and time as index column."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale Data\n",
    "\n",
    "This step is done to be sure that different features with different scales do not bias the anomaly detection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training \n",
    "\n",
    "Train the anomaly detection algorithms with Isolation Forest, One-Class SVM, Local Outlier Factor, Robust covariance on the preprocessed data to choose appropriate anomaly detection algorithms and configure them with the necessary parameters to identify anomalies in the preprocessed time series data. (Each method works differently to show these abnormals.)\n",
    "\n",
    "It is notable that these algorithms have different training procedures. For instance, Isolation Forest can be directly fitted to the data, while Local Outlier Factor uses the fit_predict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "# Calculating the outlier fraction\n",
    "normal_count = len(df[df['machine_status'] == 'NORMAL'])\n",
    "outliers_fraction = min(0.01, 1 - normal_count / len(df))\n",
    "\n",
    "# Implementing the anomaly detection algorithms\n",
    "isolation_forest = IsolationForest(contamination=outliers_fraction)\n",
    "one_class_svm = OneClassSVM(nu=outliers_fraction)\n",
    "local_outlier_factor = LocalOutlierFactor(contamination=outliers_fraction)\n",
    "robust_covariance = EllipticEnvelope(contamination=outliers_fraction)\n",
    "\n",
    "algorithms = [\n",
    "    (\"Isolation Forest\", isolation_forest),\n",
    "    (\"One-Class SVM\", one_class_svm),\n",
    "    (\"Local Outlier Factor\", local_outlier_factor),\n",
    "    (\"Robust covariance\", robust_covariance)\n",
    "]\n",
    "\n",
    "for name, algorithm in algorithms:\n",
    "    print(f\"Running {name}...\")\n",
    "    \n",
    "    # Fit the algorithm on the preprocessed data\n",
    "    #algorithm.fit(X_scaled)\n",
    "    \n",
    "    # Predict outliers/anomalies\n",
    "    #y_pred = algorithm.predict(df_resampled)\n",
    "    \n",
    "    #use this code of https://github.com/fenna/BFVM23DATASCNC5/blob/main/Study_Cases/Study_Case_Anomaly_Detection.ipynb after some bug on the implemented code in above commented\n",
    "    if name == \"Local Outlier Factor\":\n",
    "        y_pred = algorithm.fit_predict(df_resampled)\n",
    "    else:\n",
    "        y_pred = algorithm.fit(X_scaled).predict(X_scaled)\n",
    "    \n",
    "    # Reshape y_pred to match the dataframe shape\n",
    "    y_pred = y_pred.reshape(-1, 1)\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    df_resampled[name] = y_pred\n",
    "    \n",
    "    # Evaluate the performance of the algorithm\n",
    "    anomalies_detected = df_resampled[df_resampled[name] == -1]\n",
    "    print(f\"Number of anomalies detected by {name}: {len(anomalies_detected)}\")\n",
    "    print(\"-\" * 50)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most algorthims detected 2 anomalies in the data. but the meaning of each anormaly in every algorithm is alittle different:\n",
    "\n",
    "Isolation Forest: the data which have significantly different from the other data.\n",
    "\n",
    "One-Class SVM: Instances that lie far from the decision boundary of the normal data cluster.\n",
    "\n",
    "Outlier Factor: This algorithm calculates the local density deviation of a data point with respect to its neighbors to detect anomalies.\n",
    "\n",
    "Robust covariance: detect anomalies that are far from the center of the data distribution.\n",
    "\n",
    "It's notable that the number of anomalies detected by each algorithm can based on their underlying mechanisms. But the anormalies detected by One-Class SVM is much more than others, meanwhile others work similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate modeles\n",
    "\n",
    "To be sure which algorithms works better, in the following the they evalued by mathematical methods.\n",
    "\n",
    "For this at first, the machine_status had fitted for main resampled data by majority class approach based on daily status because the data are resampled data are based on daily mean.\n",
    "\n",
    "In the following code, the normal status is replace with 1 and other status replaced by -1 because the output of above algorithms are specified by 1 and -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Calculate the proportion of \"NORMAL\" and anomalous instances for each day\n",
    "day_labels = []\n",
    "for day in df_resampled.index.date:\n",
    "    day_data = df[df.index.date == day]\n",
    "    normal_count = (day_data['machine_status'] == 'NORMAL').sum()\n",
    "    anomaly_count = len(day_data) - normal_count\n",
    "    if normal_count >= anomaly_count:\n",
    "        day_labels.append(1)\n",
    "    else:\n",
    "        day_labels.append(-1)\n",
    "\n",
    "# Create a DataFrame with the calculated daily labels\n",
    "day_labels_df = pd.DataFrame({'timestamp': df_resampled.index.date, 'machine_status': day_labels})\n",
    "day_labels_df = day_labels_df.set_index('timestamp')\n",
    "\n",
    "# Merge the calculated daily labels with the resampled data\n",
    "df_resampled = df_resampled.join(day_labels_df)\n",
    "\n",
    "print(df_resampled.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dfSampl_count = len(df_resampled[df_resampled['machine_status'] == 1])\n",
    "print(f'Number of anomalies detected in the main resampled data: {df_resampled.shape[0] - normal_dfSampl_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown the number of anormalies in the main resampled data are much more than detected ones in each model.\n",
    "\n",
    "Now based on calculated 'machine_status' for resampled data, data can be divided on train and test to evaluate the scores of each model.\n",
    "\n",
    "As assignment dealing with time-series data, maybe best splitting approach is a sequential split where earlier data is used for training, and later data is used for testing. In this case the real-world scenario can be emulated for detecting anomalies based on historical information.\n",
    "\n",
    "It is notable for dividing in the following code the default proportion of divinding in the machine learning algorithms is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_scaled\n",
    "Y = df_resampled['machine_status']\n",
    "\n",
    "# Determining the index for splitting the data\n",
    "n_test = 0.2  # proportion for test data \n",
    "split_index = len(X_scaled) - int(len(X_scaled) * n_test) #calculated the train size\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = Y[:split_index], Y[split_index:]\n",
    "\n",
    "# Print the shapes of the train and test sets\n",
    "print(f\"Shape of X_train: {X_train.shape}, Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}, Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to above code it seems the train data has 123 and test data has 30 samples.\n",
    "\n",
    "In the following the \"precision and recall\" method is used because these metrics helps to understand the trade-off between correctly detecting anomalies (recall) and avoiding false positives (precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "for name, algorithm in algorithms:\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    \n",
    "    if name == \"Local Outlier Factor\":\n",
    "        y_pred = algorithm.fit_predict(X_test)\n",
    "    else:\n",
    "        algorithm.fit(X_train)\n",
    "        y_pred = algorithm.predict(X_test)\n",
    "    \n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Precision of {name}: {precision}\")\n",
    "    print(f\"Recall of {name}: {recall}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with above result again the conculsion is:\n",
    "\n",
    "A precision of 1 indicates that all the instances predicted as anomalies were actually true anomalies and this status is same for all algorithms.\n",
    "\n",
    "Based on the 1 score for recall, Isolation Forest and Robust covariance were able to correctly identify all true anomalies out of all actual anomalies. And Local Outlier Factor is almost done all status correctly. But One-Class SVM with the recall of 0.267 indicates that it identified only about 26.7% of the actual anomalies. This means that while it is good at avoiding false positives (high precision), it misses a significant portion of true anomalies (low recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this code the result just saved in the file for future processes without doing all previouse ones again \n",
    "# (However, in real projects it's better to save models outputs)\n",
    "preprocess_File = 'Data/preprocessed_data.csv'\n",
    "\n",
    "# Save the preprocessed data to a new CSV file\n",
    "df_resampled.to_csv(preprocess_File, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot sensor status\n",
    "\n",
    "To better understanding the algorithms in the following some sensors are randomly selected to visualized the status of machine in each algorithms. To better visualized each algorithm is got a specific color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select some sensors to plot as sample\n",
    "sensors = ['sensor_01', 'sensor_13', 'sensor_27', 'sensor_33', 'sensor_45', 'sensor_51']\n",
    "\n",
    "#creating subplot to visual better\n",
    "sensors_count = len(sensors)\n",
    "fig, axes = plt.subplots(nrows=int(sensors_count/2), ncols=2, figsize=(sensors_count*3, sensors_count*2))\n",
    "axes = axes.flatten()\n",
    "\n",
    "#stting color for each algorithm\n",
    "algorithm_colors = {\n",
    "    \"Isolation Forest\": 'red',\n",
    "    \"One-Class SVM\": 'pink',\n",
    "    \"Local Outlier Factor\": 'green',\n",
    "    \"Robust covariance\": 'blue'\n",
    "}\n",
    "\n",
    "for i, sensor in enumerate(sensors):\n",
    "    ax = axes[i]\n",
    "    ax.plot(df_resampled.index, df_resampled[sensor], label=sensor, color='blue')\n",
    "    \n",
    "    # Annotate anomalies for each algorithm\n",
    "    for name, algorithm in algorithms:\n",
    "        anomaly_indices = df_resampled[df_resampled[name] == -1].index\n",
    "        ax.scatter(anomaly_indices, df_resampled[df_resampled[name] == -1][sensor], c=algorithm_colors[name], label=name)\n",
    "    \n",
    "    # anomalies for the resampled data\n",
    "    real_anorm_indic = df_resampled[df_resampled['machine_status'] == -1].index\n",
    "    ax.scatter(real_anorm_indic, df_resampled[df_resampled['machine_status'] == -1][sensor], c='black', marker='x', label='machine_status')\n",
    "    \n",
    "    ax.set_xlabel('date')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(f'{sensor}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout() #adjusting layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples in the above figures shows the detected anomalities of each methods (Isolation Forest, One-Class SVM, Local Outlier Factor, Robust covariance) and besides the real anormalies on resampled data based on day are plotted. In the comparasion as above calculations shows, the Isolation Forest and Robust covariance are appear to be strong candidates for detecting anomalies and One-Class SVM may need more optimization to improve its recall and detect actual anomalies.\n",
    "\n",
    "It is notable that in this assignment the improvment of detection is based on the cleaning data, adjusting missing data and resampleing them base on daily status."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
